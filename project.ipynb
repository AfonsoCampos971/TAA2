{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAA PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 16:50:37.458559: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-28 16:50:37.458587: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "\n",
    "# Import relevant libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Data\n",
    "\n",
    "All data should be in the folder \"data\". Training data should be in the sub-folder \"training_data\" and test data in \"test_data\". The csv should be inside the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "X_train_orig = []\n",
    "y_train_orig = []\n",
    "\n",
    "COMPRESS_RATE = (128,128)\n",
    "\n",
    "X_test_orig = []\n",
    "y_test_orig = []\n",
    "\n",
    "path_train = \"data/training_data/\"\n",
    "path_test = \"data/test_data/\"\n",
    "\n",
    "tmp1 = pd.read_csv(\"data/ISBI2016_ISIC_Part3_Training_GroundTruth.csv\", header=None, names=['id', 'class'])\n",
    "tmp2 = pd.read_csv(\"data/ISBI2016_ISIC_Part3_Test_GroundTruth.csv\", header=None, names=['id', 'class'])\n",
    "\n",
    "training_truth = { tmp1['id'][i]: tmp1['class'][i] for i in range(tmp1.shape[0])}\n",
    "test_truth = { tmp2['id'][i]: tmp2['class'][i] for i in range(tmp2.shape[0])}\n",
    "\n",
    "for filename in os.listdir(path_train):\n",
    "\n",
    "    y_train_orig.append(training_truth[filename.rstrip('.jpg')] != 'benign')\n",
    "\n",
    "    image = Image.open(path_train + filename)\n",
    "    data =  np.asarray(image)\n",
    "    #plt.figure(c)\n",
    "    #plt.imshow(data)\n",
    "    data = image.resize(COMPRESS_RATE, Image.BICUBIC)\n",
    "    #print(data.size)\n",
    "    data =  np.asarray(data)\n",
    "    #plt.figure(c+100)\n",
    "    #plt.imshow(data)\n",
    "    #print(data.shape)\n",
    "    X_train_orig.append(data) \n",
    "    #if c > 10:\n",
    "    #    break\n",
    "    c += 1\n",
    "    image.close()\n",
    "\n",
    "for filename in os.listdir(path_test):\n",
    "\n",
    "    y_test_orig.append(test_truth[filename.rstrip('.jpg')])\n",
    "\n",
    "    image = Image.open(path_test + filename)\n",
    "    data =  np.asarray(image)\n",
    "    data = image.resize(COMPRESS_RATE, Image.BICUBIC)\n",
    "    data =  np.asarray(data)\n",
    "    X_test_orig.append(data) \n",
    "    image.close()\n",
    "\n",
    "X_train_orig = np.array(X_train_orig)  \n",
    "y_train_orig = np.array(y_train_orig)\n",
    "\n",
    "X_test_orig = np.array(X_test_orig)  \n",
    "y_test_orig = np.array(y_test_orig)\n",
    "\n",
    "#print(X_train_orig.shape)\n",
    "#print(y_train_orig.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (900, 128, 128, 3)\n",
      "Y_train shape:  (900,)\n",
      "X_test shape:  (379, 128, 128, 3)\n",
      "Y_test shape:  (379,)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train_orig\n",
    "y_test = y_test_orig\n",
    "\n",
    "X_train = X_train_orig/225\n",
    "X_test = X_test_orig/225\n",
    "\n",
    "print (\"X_train shape: \", X_train.shape)\n",
    "\n",
    "print (\"Y_train shape: \", y_train.shape)\n",
    "\n",
    "print (\"X_test shape: \", X_test.shape)\n",
    "\n",
    "print (\"Y_test shape: \", y_test.shape )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 (900,)\n"
     ]
    }
   ],
   "source": [
    "#plt.imshow(X_train[0])\n",
    "\n",
    "print(sum([y_train[i] == 0 for i in range(y_train.shape[0])] ), y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myModel(input_shape):\n",
    "    \"\"\" \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    # Use the suggested model in the text above to get started, and run through the whole\n",
    "    # exercise once. Then come back and add more BLOCKS. \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    #Conv2D(filters, kernel_size, .... data_format='channels_last',...)\n",
    "    # X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    \n",
    "    # #Normalize the activations of the previous layer at each batch, i.e. applies a transformation     that maintains the mean activation close to 0 and activation standard deviation close to 1.\n",
    "    # # If data_format=\"channels_last\", the axis to be normalized is axis=3. \n",
    "    # X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    # X = Activation('relu')(X)\n",
    "\n",
    "    # # MAXPOOL: helps to lower the dimension of X in height and width.\n",
    "    # X = MaxPooling2D((2, 2), name='max_pool0')(X)\n",
    "\n",
    "\n",
    "    # X = Conv2D(64, (6, 6), strides = (1, 1), name = 'conv1')(X)\n",
    "\n",
    "    # X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    # X = Activation('relu')(X)\n",
    "\n",
    "    # X = MaxPooling2D((2, 2), name='max_pool1')(X)\n",
    "\n",
    "    for i in range(4):\n",
    "        X = Conv2D(64, (3, 3), strides = (1, 1), name = f'conv{i}-{i}')(X)\n",
    "        X = Conv2D(64, (3, 3), strides = (1, 1), name = f'conv{i}-{i+1}')(X)\n",
    "\n",
    "        X = BatchNormalization(axis = 3, name = f'bn{i}')(X)\n",
    "        X = Activation('relu')(X)\n",
    "\n",
    "        X = MaxPooling2D((2, 2), name=f'max_pool{i}', padding='same')(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    # Creates the Keras model instance (object), you'll use to train/test the model.\n",
    "    print(X_input)\n",
    "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 16:51:58.965139: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-28 16:51:58.965172: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dinis-lei): /proc/driver/nvidia/version does not exist\n",
      "2022-06-28 16:51:58.965755: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = myModel(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='BinaryCrossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 16:54:30.482376: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 176947200 exceeds 10% of free system memory.\n",
      "2022-06-28 16:54:31.364095: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 142737408 exceeds 10% of free system memory.\n",
      "2022-06-28 16:54:31.421702: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 138444800 exceeds 10% of free system memory.\n",
      "2022-06-28 16:54:31.525800: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 138444800 exceeds 10% of free system memory.\n",
      "2022-06-28 16:54:32.080446: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 138444800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 43s 1s/step - loss: 0.5328 - accuracy: 0.7778\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.4630 - accuracy: 0.8100\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.4565 - accuracy: 0.8167\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.4300 - accuracy: 0.8244\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.4647 - accuracy: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbba536ea90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 7s 245ms/step - loss: 0.4522 - accuracy: 0.8178\n",
      "Loss =   0.45222753286361694\n",
      " Accuracy on Train data =  0.8177777528762817\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, batch_size=None)\n",
    "\n",
    "print (\"Loss =  \", score[0] )\n",
    "\n",
    "print (\" Accuracy on Train data = \", score[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 3s 244ms/step - loss: 1.8219 - accuracy: 0.2032\n",
      "Loss =   1.821908950805664\n",
      " Accuracy on Test data =  0.20316623151302338\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Evaluate the model on test data  \n",
    "score = model.evaluate(X_test, y_test, batch_size=None)\n",
    "\n",
    "\n",
    "print (\"Loss =  \", score[0] )\n",
    "\n",
    "print (\" Accuracy on Test data = \", score[1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"HappyModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " zero_padding2d_13 (ZeroPadd  (None, 70, 70, 3)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv0 (Conv2D)              (None, 64, 64, 32)        4736      \n",
      "                                                                 \n",
      " bn0 (BatchNormalization)    (None, 64, 64, 32)        128       \n",
      "                                                                 \n",
      " activation_41 (Activation)  (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " max_pool0 (MaxPooling2D)    (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 27, 27, 64)        73792     \n",
      "                                                                 \n",
      " bn1 (BatchNormalization)    (None, 27, 27, 64)        256       \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 27, 27, 64)        0         \n",
      "                                                                 \n",
      " max_pool1 (MaxPooling2D)    (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 10, 10, 128)       204928    \n",
      "                                                                 \n",
      " bn2 (BatchNormalization)    (None, 10, 10, 128)       512       \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 10, 10, 128)       0         \n",
      "                                                                 \n",
      " max_pool2 (MaxPooling2D)    (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " fc (Dense)                  (None, 1)                 3201      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,553\n",
      "Trainable params: 287,105\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "688facd3c8c2c06ed3d555928b3a1faf5c3e87b2b60907918d156c669ff76b9b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
